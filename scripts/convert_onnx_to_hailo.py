import os
import argparse
import numpy as np

from hailo_sdk_client import ClientRunner


def build_model_script(optimization_level=1, compression_level=0,
                       calibset_size=200, batch_size=8):
    """
    Hailo ëª¨ë¸ ìµœì í™”/ì–‘ìí™” ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
    """
    lines = [
        f"model_optimization_flavor(optimization_level={optimization_level}, "
        f"compression_level={compression_level})\n",
        # ì»´íŒŒì¼ëŸ¬ ìµœì í™” ë ˆë²¨ë§Œ ìµœëŒ€í•œ ì¼œì£¼ê¸°
        "performance_param(compiler_optimization_level=max)\n",
        f"model_optimization_config(calibration, batch_size={batch_size}, "
        f"calibset_size={calibset_size})\n",
    ]
    return "".join(lines)


def get_model_config(model_name: str):
    """
    ê° ëª¨ë¸(yolov8_face, facenet)ì— ëŒ€í•œ ê¸°ë³¸ ì„¤ì •
    """
    if model_name == "yolov8_face":
        return {
            "onnx_path": "yolov8_face_320.onnx",
            "net_name": "yolov8_face",
            "input_height": 320,
            "input_width": 320,
            "input_ch": 3,
            # ğŸ”¥ Hailo ì—ëŸ¬ ë©”ì‹œì§€ê°€ ì¶”ì²œí•´ ì¤€ end node
            "end_nodes": ["/model.22/Concat_3"],
        }
    elif model_name == "facenet":
        return {
            "onnx_path": "facenet.onnx",
            "net_name": "facenet",
            # Facenet ì…ë ¥ í¬ê¸° (í•„ìš”í•˜ë©´ 112ë¡œ ìˆ˜ì • ê°€ëŠ¥)
            "input_height": 160,
            "input_width": 160,
            "input_ch": 3,
            "end_nodes": None,   # facenetì€ ì „ì²´ ê·¸ë˜í”„ ì‚¬ìš©
        }
    else:
        raise ValueError(f"Unknown model name: {model_name}")


def create_random_calib_data(input_height, input_width, input_ch, calib_size):
    """
    ëœë¤ ì´ë¯¸ì§€ë¡œ calibration ë°ì´í„° ìƒì„±
    shape: (N, H, W, C)
    """
    calib_data = np.random.randint(
        0, 255,
        size=(calib_size, input_height, input_width, input_ch),
        dtype=np.uint8
    )
    return calib_data


def convert_single_model(cfg, args):
    """
    ONNX í•˜ë‚˜ë¥¼:
      1) translate_onnx_model â†’ parsed HAR
      2) optimize(calib_data) â†’ quantized HAR
      3) compile() â†’ HEF
    ê¹Œì§€ ì²˜ë¦¬
    """
    onnx_path = cfg["onnx_path"]
    net_name = cfg["net_name"]
    h = cfg["input_height"]
    w = cfg["input_width"]
    c = cfg["input_ch"]

    if not os.path.isfile(onnx_path):
        raise FileNotFoundError(f"ONNX file not found: {onnx_path}")

    print(f"[INFO] Converting model: {net_name}")
    print(f"[INFO] ONNX path: {onnx_path}")
    print(f"[INFO] Input shape: (1, {c}, {h}, {w})")

    # 1) ONNX â†’ Hailo ë‚´ë¶€ í¬ë§· (parse)
    runner = ClientRunner(hw_arch=args.hw_arch)

    # ğŸ”¥ yolov8_faceëŠ” DFL Reshape ì—ëŸ¬ ë•Œë¬¸ì— end_node_names í•„ìš”
    end_nodes = cfg.get("end_nodes", None)

    if end_nodes:
        hn, npz = runner.translate_onnx_model(
            onnx_path,
            net_name,
            end_node_names=end_nodes,
        )
    else:
        hn, npz = runner.translate_onnx_model(
            onnx_path,
            net_name,
        )

    parsed_har = f"{net_name}_parsed.har"
    runner.save_har(parsed_har)
    print(f"[INFO] Saved parsed HAR: {parsed_har}")

    # 2) Calibration ë°ì´í„° ìƒì„±
    calib_data = create_random_calib_data(
        h, w, c, calib_size=args.calib_size
    )
    print(f"[INFO] Calibration data shape: {calib_data.shape}")

    # 3) ëª¨ë¸ ìŠ¤í¬ë¦½íŠ¸ ë¡œë“œ (ìµœì í™” / ì–‘ìí™” ì„¤ì •)
    model_script = build_model_script(
        optimization_level=args.op,
        compression_level=args.comp,
        calibset_size=args.calib_size,
        batch_size=args.calib_batch_size,
    )
    runner.load_model_script(model_script)

    # 4) Optimize(=ì–‘ìí™”) ì‹¤í–‰
    print("[INFO] Running optimization (quantization)...")
    runner.optimize(calib_data)

    quant_har = f"{net_name}_quantized.har"
    runner.save_har(quant_har)
    print(f"[INFO] Saved quantized HAR: {quant_har}")

    # 5) Compile â†’ HEF ìƒì„±
    print("[INFO] Compiling to HEF...")
    hef = runner.compile()
    hef_path = f"{net_name}.hef"
    with open(hef_path, "wb") as f:
        f.write(hef)
    print(f"[INFO] Saved HEF: {hef_path}")
    print("=========================================")


def main():
    parser = argparse.ArgumentParser(
        description="Convert ONNX models (yolov8_face / facenet) to Hailo HEF."
    )
    parser.add_argument(
        "--models",
        nargs="+",
        default=["yolov8_face", "facenet"],
        help="ë³€í™˜í•  ëª¨ë¸ ì´ë¦„ ë¦¬ìŠ¤íŠ¸. ì˜ˆ) --models yolov8_face facenet",
    )
    parser.add_argument(
        "--hw-arch",
        type=str,
        default="hailo8",
        help="Target HW arch (ê¸°ë³¸: hailo8)",
    )
    parser.add_argument(
        "--calib-size",
        type=int,
        default=200,
        help="Calibration ìƒ˜í”Œ ê°œìˆ˜ (ê¸°ë³¸: 200)",
    )
    parser.add_argument(
        "--calib-batch-size",
        dest="calib_batch_size",
        type=int,
        default=8,
        help="Optimize ì‹œ batch_size (ê¸°ë³¸: 8)",
    )
    parser.add_argument(
        "--op",
        type=int,
        default=1,
        help="optimization_level (ì—°êµ¬ì‹¤ ì½”ë“œì—ì„œ op)",
    )
    parser.add_argument(
        "--comp",
        type=int,
        default=0,
        help="compression_level (ì—°êµ¬ì‹¤ ì½”ë“œì—ì„œ comp)",
    )

    args = parser.parse_args()

    for name in args.models:
        cfg = get_model_config(name)
        convert_single_model(cfg, args)


if __name__ == "__main__":
    main()
